{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s14YH6D4pBzq"
   },
   "source": [
    "# Buscalibre Numeric Model\n",
    "\n",
    "The preprocessed has two types of data, numeric and text data. Here, we try to build an estimator using only the numeric part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L29d5QCts0CS"
   },
   "source": [
    "## Libraries and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX6IKSn4s7T9"
   },
   "source": [
    "Import the neccesary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kuxUuKYqszh3",
    "outputId": "1e8cdc5d-bae4-4018-bc01-b15f0fafa01e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xJSKoY5tHRS"
   },
   "source": [
    "Upload the Training dataset, and shuffle as it becomes sectioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder = os.getcwd().replace(\"\\\\\", \"/\") + \"/\"\n",
    "path_parent = os.path.dirname(os.getcwd()).replace(\"\\\\\", \"/\") + \"/\"\n",
    "train = pd.read_csv(path_parent + \"data_analysis/train_2.csv\")\n",
    "test = pd.read_csv(path_parent + \"data_analysis/test_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "95Cbr5NztI4I"
   },
   "outputs": [],
   "source": [
    "train = train.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "X = train.drop(columns=[\"isbn\", \"review\", \"topic\", \"review_cleaned\"])\n",
    "y = train[\"topic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GH1PZkCwtfid"
   },
   "source": [
    "And define the cross validated scorer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oEThnwRGtp5Z"
   },
   "outputs": [],
   "source": [
    "def cross_score(model, k=10):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=111)\n",
    "    scores = cross_val_score(model, X, y, cv=kf)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46BiZN245Ws8"
   },
   "source": [
    "### Common Label\n",
    "\n",
    "As we saw in the Data Exploration Analysis, the topic \"grandes-descuentos\" has the greatest number of samples. So an starting prediction is to assume every label belongs to it.\n",
    "\n",
    "We get an score of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CoQHDs_5WUj",
    "outputId": "83a35838-4a3d-40c7-cc63-1f14e2d4cf7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with the common label has an accuracy of: 41.79%.\n"
     ]
    }
   ],
   "source": [
    "y_pred = [\"grandes-descuentos\" for i in range(len(y))]\n",
    "print(f\"Predicting with the common label has an accuracy of: {accuracy_score(y, y_pred):.2%}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vslyx9Imt29Y"
   },
   "source": [
    "## Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkYo8frHuD9-"
   },
   "source": [
    "We are going to use various simple predictors provided by Scikit Learn and Tensorflow. \n",
    "\n",
    "The choice of hyperparameters was done using Optuna package and Google servers for about 5-10 hours for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENQ0vPftvbFb"
   },
   "source": [
    "Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKRHgf7avZGq",
    "outputId": "ffff656c-bf37-4a96-c1b4-983296abaa3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier has an accuracy of 68.27%\n"
     ]
    }
   ],
   "source": [
    "ovr_rfc = OneVsRestClassifier(RandomForestClassifier(**{\n",
    "    'n_estimators': 334,\n",
    "    'criterion': 'entropy',\n",
    "    'max_depth': 42,\n",
    "    'min_samples_split': 9,\n",
    "    'min_samples_leaf': 4,\n",
    "    'max_features': 0.45448755763486154,\n",
    "    'random_state': 555\n",
    "}))\n",
    "acc = cross_score(ovr_rfc)\n",
    "print(f\"Random Forest Classifier has an accuracy of {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHPCOkjqvw1K"
   },
   "source": [
    "Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N9LUxR7ivvAN",
    "outputId": "341cfa8a-8a96-4368-eeb2-abb6579a7e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression has an accuracy of 66.39%\n"
     ]
    }
   ],
   "source": [
    "logreg = make_pipeline(StandardScaler(), MinMaxScaler(), LogisticRegression(\n",
    "    C=8.261486231908338,\n",
    "    tol=0.8728213920467933,\n",
    "    intercept_scaling=9.117615728181427,\n",
    "    multi_class=\"multinomial\",\n",
    "    max_iter=10_000,\n",
    "    random_state=555\n",
    "))\n",
    "acc = cross_score(logreg)\n",
    "print(f\"Logistic Regression has an accuracy of {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wtk4Ywbmv1zt"
   },
   "source": [
    "XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lwtaRxAev0X9",
    "outputId": "0be474f8-96c0-4a53-c708-9a25694b7385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier has an accuracy of 67.74%\n"
     ]
    }
   ],
   "source": [
    "ovr_xgb = OneVsRestClassifier(XGBClassifier(**{\n",
    "    'n_estimators': 378,\n",
    "    'learning_rate': 0.02950073992817461,\n",
    "    'base_score': 0.9187179242725662,\n",
    "    'verbosity': 0,\n",
    "    'use_label_encoder': False,\n",
    "    'random_state': 555\n",
    "}))\n",
    "\n",
    "acc = cross_score(ovr_xgb)\n",
    "\n",
    "print(f\"XGBoost Classifier has an accuracy of {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDnh4gb0v7Ze"
   },
   "source": [
    "Light GBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vW1XlQITv-GJ",
    "outputId": "b6fdd221-e7bd-4c2f-c50d-1715bf3d0042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBoost has an accuracy of 66.77%\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(**{\n",
    "    'num_leaves': 27,\n",
    "    'n_estimators': 268,\n",
    "    'learning_rate': 0.018813923117324143,\n",
    "    'random_state': 555\n",
    "})\n",
    "\n",
    "acc = cross_score(lgb)\n",
    "\n",
    "print(f\"Light GBoost has an accuracy of {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRCWb0PUwCwX"
   },
   "source": [
    "Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLOXGbTDwEFC",
    "outputId": "99a538bb-618a-4f16-ba67-18abd5fb7f22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Boost Classifier has an accuracy of 67.52%\n"
     ]
    }
   ],
   "source": [
    "ovr_cat = OneVsRestClassifier(CatBoostClassifier(**{\n",
    "    'iterations': 330,\n",
    "    'learning_rate': 0.043379595491767745,\n",
    "    'depth': 7,\n",
    "    'l2_leaf_reg': 0.5416613355579589,\n",
    "    'border_count': 212,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'verbose': False,\n",
    "    'random_state': 555\n",
    "}))\n",
    "\n",
    "acc = cross_score(ovr_cat)\n",
    "\n",
    "print(f\"Cat Boost Classifier has an accuracy of {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa71a5bRwGI2"
   },
   "source": [
    "Forward Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZThaZpKwJ9b",
    "outputId": "11532db3-34e7-4ca2-be77-816a43e7c085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Classifier has an accuracy of 65.26%\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(555)\n",
    "class NetworkClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, ini_neurons=60, optimizer=\"adam\", epochs=200, validation_split=0.3):\n",
    "        self.ini_neurons = ini_neurons\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.validation_split = validation_split\n",
    "        self.model = Sequential()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_enc = pd.get_dummies(y)\n",
    "        self.cols = y_enc.columns\n",
    "        y_np = y_enc.to_numpy()\n",
    "        X_np = X.to_numpy()\n",
    "        self.model.add(Dense(self.ini_neurons, input_shape=(X.shape[1], ), activation=\"relu\"))\n",
    "        self.model.add(Dense(13, activation=\"softmax\"))\n",
    "        self.model.compile(\n",
    "            optimizer=self.optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "        )\n",
    "        self.model.fit(\n",
    "            X_np, y_np, epochs=self.epochs, validation_split=self.validation_split, verbose=0\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_np = X.to_numpy()\n",
    "        y_hat = self.model.predict(X_np)\n",
    "        y_df = pd.DataFrame(data=y_hat, columns=self.cols)\n",
    "        y_pred = y_df.idxmax(axis=1)\n",
    "        return y_pred\n",
    "\n",
    "nc = NetworkClassifier()\n",
    "acc = cross_score(nc, k=6)\n",
    "print(f\"Network Classifier has an accuracy of {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGIqkz8DwSEP"
   },
   "source": [
    "# Weighted Voting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0Wo_sggxVMz"
   },
   "source": [
    "One simple way to combine and (posible) improve your predictions, is building a voting classifier. Each Estimator makes its own prediction, and then we save the most voted label. Also, one can put weights on each estimator, to favor it over the others, and get an overall improved prediction.\n",
    "\n",
    "Again, the weights were chosen using Optuna searching functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBaovUkqzX-H"
   },
   "source": [
    "Define and call the Weighted Averaging Estimator class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "s_XYJzBvwQ5-"
   },
   "outputs": [],
   "source": [
    "class WeightedAveragingEstimator(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.cols = pd.get_dummies(y).columns\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        sum = pd.DataFrame(dtype=float, columns=self.cols)\n",
    "        for i, model in enumerate(self.models_):\n",
    "            y_pred_ = model.predict(X)\n",
    "            y_hat = self.weights[i] * pd.get_dummies(y_pred_)\n",
    "            sum = sum.add(y_hat, fill_value=0)\n",
    "        sum.fillna(value=0)\n",
    "        y_pred = sum.idxmax(axis=1)\n",
    "        return y_pred\n",
    "\n",
    "models = (\n",
    "    OneVsRestClassifier(RandomForestClassifier(**{\n",
    "        'n_estimators': 334,\n",
    "        'criterion': 'entropy',\n",
    "        'max_depth': 42,\n",
    "        'min_samples_split': 9,\n",
    "        'min_samples_leaf': 4,\n",
    "        'max_features': 0.45448755763486154,\n",
    "        'random_state': 555\n",
    "    })),\n",
    "    make_pipeline(StandardScaler(), MinMaxScaler(), LogisticRegression(\n",
    "        C=8.261486231908338,\n",
    "        tol=0.8728213920467933,\n",
    "        intercept_scaling=9.117615728181427,\n",
    "        multi_class=\"multinomial\",\n",
    "        max_iter=10_000,\n",
    "        random_state=555\n",
    "    )),\n",
    "    OneVsRestClassifier(XGBClassifier(**{\n",
    "        'n_estimators': 378,\n",
    "        'learning_rate': 0.02950073992817461,\n",
    "        'base_score': 0.9187179242725662,\n",
    "        'verbosity': 0,\n",
    "        'use_label_encoder': False,\n",
    "        'random_state': 555\n",
    "    })),\n",
    "    LGBMClassifier(**{\n",
    "        'num_leaves': 27,\n",
    "        'n_estimators': 268,\n",
    "        'learning_rate': 0.018813923117324143,\n",
    "        'random_state': 555\n",
    "    }),\n",
    "    OneVsRestClassifier(CatBoostClassifier(**{\n",
    "        'iterations': 330,\n",
    "        'learning_rate': 0.043379595491767745,\n",
    "        'depth': 7,\n",
    "        'l2_leaf_reg': 0.5416613355579589,\n",
    "        'border_count': 212,\n",
    "        'loss_function': 'MultiClass',\n",
    "        'verbose': False,\n",
    "        'random_state': 555\n",
    "    })),\n",
    "    NetworkClassifier()\n",
    ")\n",
    "weights = [0.599, 0.781, 0.76, 0.425, 0.678, 0.449]\n",
    "wae = WeightedAveragingEstimator(models=models, weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gZWgYUj0DMa"
   },
   "source": [
    "WAE gets an score of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXMpoYBX0CwU",
    "outputId": "ff51adf0-a8ba-406d-efbf-47613814880a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Averaging Estimator has an accuracy of 67.93%\n"
     ]
    }
   ],
   "source": [
    "acc = cross_score(wae, k=6)\n",
    "print(f\"Weighted Averaging Estimator has an accuracy of {acc:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Buscalibre_Numeric_ML_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
